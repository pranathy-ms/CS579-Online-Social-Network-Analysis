{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import config\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Initialize Reddit\n",
    "reddit = praw.Reddit(client_id=config.client_id,\n",
    "                     client_secret=config.client_secret,\n",
    "                     user_agent=config.user_agent)\n",
    "\n",
    "# Lists to store data\n",
    "posts_data = []\n",
    "comments_data = []\n",
    "title = []\n",
    "post_author = []\n",
    "comment_authors = []\n",
    "\n",
    "#represent in a dataframe    \n",
    "df = pd.DataFrame(columns=['Subreddit','Title','PostAuthor','CommentAuthors'])\n",
    "\n",
    "# Choose subreddit\n",
    "subreddit_names = ['OnePiece', 'Naruto', 'dbz', 'OnePunchMan', 'ShingekiNoKyojin', 'JuJutsuKaisen','BokuNoHeroAcademia','HunterXHunter','Berserk','sololeveling','bleach','BlackClover','SpyxFamily','ChainsawMan','deathnote']\n",
    "for names in subreddit_names:\n",
    "    subreddit = reddit.subreddit(names)\n",
    "    # Fetch posts\n",
    "    comment_count = 0\n",
    "    all_comments = []\n",
    "    for post in subreddit.hot(limit=25):  # Adjust limit as needed\n",
    "        number_of_comments = len(post.comments.list())\n",
    "        if not post.author:\n",
    "            post_username = 'deleted user'\n",
    "        else:\n",
    "            post_username = post.author.name\n",
    "    \n",
    "        #Comments\n",
    "       \n",
    "        post.comments.replace_more(limit=0)  # Load all comments\n",
    "        for comment in post.comments.list():\n",
    "            if not comment.author:\n",
    "                comment_username = 'deleted user'\n",
    "            else:\n",
    "                comment_username = comment.author.name\n",
    "            \n",
    "            reply_authors = []\n",
    "            for second_level_comment in comment.replies:\n",
    "                if not second_level_comment.author:\n",
    "                    second_level_comment_username = 'deleted user'\n",
    "                else:\n",
    "                    second_level_comment_username = second_level_comment.author.name\n",
    "                reply_authors.append(second_level_comment_username)\n",
    "\n",
    "            comment_authors.append([comment_username,reply_authors])\n",
    "            \n",
    "            title.append(post.title)\n",
    "            post_author.append(post_username)\n",
    "            all_comments.append(comment_authors)\n",
    "            df.loc[len(df)] = [names,post.title,post_username,comment_authors[-1]]\n",
    "\n",
    "\n",
    "\n",
    "print(df.shape)  \n",
    "print(df)\n",
    "df.to_csv('exported_dataframe.csv', index=False, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Initialize a dictionary to hold user data\n",
    "user_subreddits = defaultdict(lambda: {'count': 0, 'subreddits': set()})\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    # Track the post author\n",
    "    user_subreddits[row['PostAuthor']]['count'] += 1\n",
    "    user_subreddits[row['PostAuthor']]['subreddits'].add(row['Subreddit'])\n",
    "\n",
    "    # Track comment authors and reply authors\n",
    "    for comment_author_replies in row['CommentAuthors']:\n",
    "        # Ensure comment_author_replies is a list with at least one element (the main comment author)\n",
    "        if isinstance(comment_author_replies, list) and len(comment_author_replies) > 0:\n",
    "            main_author = comment_author_replies[0]  # Main comment author\n",
    "            user_subreddits[main_author]['count'] += 1\n",
    "            user_subreddits[main_author]['subreddits'].add(row['Subreddit'])\n",
    "\n",
    "            # Check if there are reply authors and they are in a list\n",
    "            if len(comment_author_replies) > 1 and isinstance(comment_author_replies[1], list):\n",
    "                for reply_author in comment_author_replies[1]:\n",
    "                    user_subreddits[reply_author]['count'] += 1\n",
    "                    user_subreddits[reply_author]['subreddits'].add(row['Subreddit'])\n",
    "\n",
    "# Convert to DataFrame\n",
    "users_data = []\n",
    "for user, data in user_subreddits.items():\n",
    "    if len(data['subreddits']) > 1:  # Users appearing in multiple subreddits\n",
    "        users_data.append([user, data['count'], \", \".join(data['subreddits'])])\n",
    "\n",
    "df_users_in_multiple_subreddits = pd.DataFrame(users_data, columns=['User', 'Occurrences', 'Subreddits'])\n",
    "\n",
    "df_users_in_multiple_subreddits = df_users_in_multiple_subreddits.loc[~df_users_in_multiple_subreddits['User'].isin(['AutoModerator', 'deleted user'])]\n",
    "\n",
    "print(df_users_in_multiple_subreddits)\n",
    "df_users_in_multiple_subreddits.to_csv('optimized_new.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'df_users_in_multiple_subreddits' DataFrame is prepared as before\n",
    "# and you have a CSV file that maps users to subreddits correctly.\n",
    "\n",
    "df_users = pd.read_csv('optimized_new.csv')\n",
    "\n",
    "# Generating a new graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Define colors for each subreddit\n",
    "subreddit_colors = {\n",
    "    'OnePiece': '#FF6347',  # Tomato\n",
    "    'Naruto': '#FFD700',  # Gold\n",
    "    'dbz': '#FF4500',  # OrangeRed\n",
    "    'OnePunchMan': '#DA70D6',  # Orchid\n",
    "    'ShingekiNoKyojin': '#2E8B57',  # SeaGreen\n",
    "    'JuJutsuKaisen': '#6A5ACD',  # SlateBlue\n",
    "    'BokuNoHeroAcademia': '#20B2AA',  # LightSeaGreen\n",
    "    'HunterXHunter': '#DB7093',  # PaleVioletRed\n",
    "    'Berserk': '#8B0000',  # DarkRed\n",
    "    'sololeveling': '#C71585',  # MediumVioletRed\n",
    "    'bleach': '#1E90FF',  # DodgerBlue\n",
    "    'BlackClover': '#3CB371',  # MediumSeaGreen\n",
    "    'SpyxFamily': '#FFA07A',  # LightSalmon\n",
    "    'ChainsawMan': '#D2691E',  # Chocolate\n",
    "    'deathnote': '#696969',  # DimGray\n",
    "}\n",
    "\n",
    "# Add nodes with attributes\n",
    "for _, row in df_users.iterrows():\n",
    "    user = row['User']\n",
    "    subreddit = row['Subreddits']  # Assuming 'Subreddits' is the column containing subreddit values\n",
    "    G.add_node(user, type='user', subreddit=subreddit)\n",
    "\n",
    "# Add edges\n",
    "for i, row_i in df_users.iterrows():\n",
    "    user_i = row_i['User']\n",
    "    subreddits_i = set(row_i['Subreddits'].split(', '))\n",
    "    for j, row_j in df_users.iterrows():\n",
    "        if i < j:  # Ensure each pair is processed only once\n",
    "            user_j = row_j['User']\n",
    "            subreddits_j = set(row_j['Subreddits'].split(', '))\n",
    "            shared_subreddits = subreddits_i.intersection(subreddits_j)\n",
    "            \n",
    "            for subreddit in shared_subreddits:\n",
    "                # Add an edge for each shared subreddit\n",
    "                G.add_edge(user_i, user_j, color=subreddit_colors[subreddit], label=subreddit)\n",
    "\n",
    "\n",
    "# Assuming G is your pre-defined graph\n",
    "# Initialize the circular layout\n",
    "pos = nx.spring_layout(G, seed=109)\n",
    "\n",
    "# Drawing the graph using the circular layout\n",
    "plt.figure(figsize=(50, 50))  # Adjust figure size to your preference\n",
    "\n",
    "# Draw nodes\n",
    "nx.draw_networkx_nodes(G, pos,node_color='black', node_size=150)\n",
    "\n",
    "# Draw edges\n",
    "edges = G.edges(data=True)\n",
    "edge_colors = [edge[2]['color'] for edge in edges]  # Extract color from edge attribute\n",
    "nx.draw_networkx_edges(G, pos, edge_color=edge_colors, width=2)\n",
    "\n",
    "\n",
    "\n",
    "plt.axis('off')  # Turn off the axis\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieving the count of nodes and edges\n",
    "number_of_nodes = G.number_of_nodes()\n",
    "number_of_edges = G.number_of_edges()\n",
    "\n",
    "print(f\"Total Nodes in the Graph: {number_of_nodes}\")\n",
    "print(f\"Total Edges in the Graph: {number_of_edges}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate degree centrality\n",
    "degree_centrality = nx.degree_centrality(G)\n",
    "\n",
    "plt.hist(degree_centrality.values(), bins=10, edgecolor='black')\n",
    "plt.title('Degree Centrality Histogram')\n",
    "plt.xlabel('Degree Centrality')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Calculate betweenness centrality\n",
    "betweenness_centrality = nx.betweenness_centrality(G)\n",
    "print(\"Betweenness Centrality:\", betweenness_centrality)\n",
    "\n",
    "# Calculate clustering coefficient\n",
    "clustering_coefficient = nx.clustering(G)\n",
    "print(\"Clustering Coefficient:\", clustering_coefficient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame to store degree centrality and corresponding subreddit\n",
    "degree_centrality_df = pd.DataFrame(columns=['Node', 'Degree Centrality', 'Subreddit'])\n",
    "\n",
    "i = 0\n",
    "# Populate the DataFrame with degree centrality and corresponding subreddit\n",
    "for node, centrality in degree_centrality.items():\n",
    "    degree_centrality_df.loc[len(degree_centrality_df)] = {'Node': node, 'Degree Centrality': centrality, 'Subreddit': G.nodes[node]['subreddit']}\n",
    "    i += 1\n",
    "\n",
    "degree_centrality_df = degree_centrality_df.sort_values(by='Degree Centrality', ascending=False)\n",
    "\n",
    "\n",
    "# Print the most active user based on degree centrality\n",
    "print(\"Most active user based on degree centrality:\", degree_centrality_df.iloc[0]['Node'])\n",
    "print(\"Degree centrality:\", degree_centrality_df.iloc[0]['Degree Centrality'])\n",
    "print(\"Subreddit:\", degree_centrality_df.iloc[0]['Subreddit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betweenness_centrality_df = pd.DataFrame(columns=['Node', 'Subreddit', 'Betweenness Centrality'])\n",
    "\n",
    "i = 0\n",
    "# Populate the DataFrame with degree centrality and corresponding subreddit\n",
    "for node, centrality in betweenness_centrality.items():\n",
    "    betweenness_centrality_df.loc[len(betweenness_centrality_df)] = {'Node': node, 'Betweenness Centrality': centrality, 'Subreddit': G.nodes[node]['subreddit']}\n",
    "    i += 1\n",
    "\n",
    "# Sort DataFrame by betweenness centrality in descending order\n",
    "betweenness_centrality_df = betweenness_centrality_df.sort_values(by='Betweenness Centrality', ascending=False)\n",
    "\n",
    "# Print the user with the highest betweenness centrality\n",
    "print(\"User with the highest betweenness centrality:\", betweenness_centrality_df.iloc[0]['Node'])\n",
    "print(\"Betweenness centrality:\", betweenness_centrality_df.iloc[0]['Betweenness Centrality'])\n",
    "print(\"Subreddit:\", betweenness_centrality_df.iloc[0]['Subreddit'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert clustering coefficient dictionary to DataFrame\n",
    "clustering_coefficient_df = pd.DataFrame(columns=['Node', 'Clustering Coefficient', 'Subreddit'])\n",
    "\n",
    "# Populate the DataFrame with clustering coefficient and corresponding subreddit\n",
    "for node, coefficient in clustering_coefficient.items():\n",
    "    subreddit = G.nodes[node]['subreddit']\n",
    "    clustering_coefficient_df.loc[len(clustering_coefficient_df)] = {'Node': node, 'Clustering Coefficient': coefficient, 'Subreddit': subreddit}\n",
    "\n",
    "# Sort DataFrame by clustering coefficient in descending order\n",
    "clustering_coefficient_df = clustering_coefficient_df.sort_values(by='Clustering Coefficient', ascending=False)\n",
    "\n",
    "# Print the subreddit with the highest clustering coefficient\n",
    "print(\"User with the highest clustering coefficient:\", clustering_coefficient_df.iloc[0]['Node'])\n",
    "print(\"Clustering coefficient:\",clustering_coefficient_df.iloc[0]['Clustering Coefficient'])\n",
    "print(\"Subreddit: \",clustering_coefficient_df.iloc[0]['Subreddit'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Based on all the generated metrics, we get to identify the subreddits with the most popularity, impact and users who are well connected with other subreddits.\")\n",
    "print(\"Publicizing anything in these subreddits, has better reach than the ones analyzed by us.\")\n",
    "degree_subreddits = degree_centrality_df.iloc[0]['Subreddit'].split(', ')\n",
    "betweenness_subreddits = betweenness_centrality_df.iloc[0]['Subreddit'].split(', ')\n",
    "clustering_subreddits = clustering_coefficient_df.iloc[0]['Subreddit'].split(', ')\n",
    "\n",
    "# Merge all subreddits and remove duplicates\n",
    "all_subreddits = list(set(degree_subreddits + betweenness_subreddits + clustering_subreddits))\n",
    "\n",
    "# Print the merged list of subreddits\n",
    "print(\"Merged list of subreddits:\", all_subreddits)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
